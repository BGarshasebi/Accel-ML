import numpy as np
import pandas as pd
from sklearn.utils import shuffle
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import KFold

# Load your own CSV data
data = pd.read_csv(r"filename.csv")

# List columns of the dataframe
print(data.columns.tolist())

# Define the dependent and independent variables
dependent_var = "dependent_var"  # Change this to your dependent variable
independent_vars = ["independent_var1", "independent_var2", ...]  # Change these to your independent variables

# Prepare dependent variable
y = data[dependent_var].values

# Prepare independent variables
X = data[independent_vars].values

# Initialize KFold
kf = KFold(n_splits=5, shuffle=True)

# Lists to store results
rf_all = []
rf_mae_all = []
best_mae = float('inf')
feature_importance_all = []

# Loop over repeats
for repeat in range(5):
    print('Repeat:', repeat)
    
    test_score_all_rf = []
    test_score_all_rf_MAE = []
    feature_importance = []
    
    # K-Fold cross-validation
    for i, (train_index, test_index) in enumerate(kf.split(X)):
        print("Fold:", i)
        
        # Shuffle and split training data into train and validation sets
        train_index_shuffle = shuffle(train_index)
        sub_train_index = train_index_shuffle[:int(len(train_index) * 0.875)]
        sub_valid_index = train_index_shuffle[int(len(train_index) * 0.875):]
        
        train_feature = X[sub_train_index]
        train_label = y[sub_train_index]
        
        valid_feature = X[sub_valid_index]
        valid_label = y[sub_valid_index]
        
        test_feature = X[test_index]
        test_label = y[test_index]
        
        n_estimators = 500
        max_depth = 20
        
        # Train the RandomForestRegressor
        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)
        model.fit(train_feature, train_label)
        
        valid_score = model.score(valid_feature, valid_label)
                
        if valid_score > best_mae:
            test_score = model.score(test_feature, test_label)
            pred = model.predict(test_feature)
            best_MAE = mean_absolute_error(test_label, pred)
            best_model = model
            best_feature_importance = model.feature_importances_
        
        print('Test score:', test_score)
        test_score_all_rf.append(test_score)
        test_score_all_rf_MAE.append(best_MAE)
        feature_importance.append(best_feature_importance)
        print('MAE:', best_MAE)
        print('')
    
    print('Mean accuracy in this repeat:', np.mean(test_score_all_rf))
    print('Mean MAE score in this repeat:', np.mean(test_score_all_rf_MAE))
    
    rf_all.append(np.mean(test_score_all_rf))
    rf_mae_all.append(np.mean(test_score_all_rf_MAE))
    
print('Mean accuracy for all repeats:', np.mean(rf_all))
print('Mean MAE for all repeats:', np.mean(rf_mae_all))
print('Best MAE:', best_mae)
print('Feature Importance of the Best Model:', best_feature_importance)
